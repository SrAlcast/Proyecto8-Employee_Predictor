# üåü Employee Predictor: Unlock Workplace Insights 

![Employee Predictor](https://raw.githubusercontent.com/SrAlcast/Proyecto8-Employee_Predictor/refs/heads/main/src/imagen%20README.jpg?token=GHSAT0AAAAAACW5JJGYIIDOZME6LEIQDVUIZ2M7IYQ)

## üìñ Introducci√≥n

La retenci√≥n de empleados es un desaf√≠o cr√≠tico para las organizaciones de todo el mundo. Comprender por qu√© los empleados deciden quedarse o irse puede impactar significativamente el desempe√±o y la cultura de una empresa. Este proyecto tiene como objetivo predecir la retenci√≥n de empleados utilizando t√©cnicas avanzadas de machine learning, revelando los factores clave que impulsan la satisfacci√≥n y las decisiones de los empleados.

A trav√©s del an√°lisis de diversos conjuntos de datos, este proyecto no solo construye modelos predictivos, sino que tambi√©n proporciona recomendaciones pr√°cticas para fomentar un entorno laboral m√°s positivo. Desde la limpieza de datos hasta la optimizaci√≥n de modelos, exploramos a fondo las din√°micas de la retenci√≥n de empleados.

## üóÇÔ∏è Estructura del Proyecto

El repositorio est√° organizado de la siguiente manera:

```
‚îú‚îÄ‚îÄ data/                # Conjuntos de datos crudos y procesados
‚îú‚îÄ‚îÄ encoders/            # Pkl para estandarizar y encodear datos
‚îú‚îÄ‚îÄ models/              # Modelos de machine learning entrenados
‚îú‚îÄ‚îÄ notebooks/           # Notebooks de Jupyter para an√°lisis y modelado
‚îú‚îÄ‚îÄ results/             # Datos procesados y resultados
‚îú‚îÄ‚îÄ src/                 # C√≥digo fuente para preprocesamiento y modelado
‚îú‚îÄ‚îÄ streamlit/           # C√≥digo para la ejecucion de streamlit con el modelo
‚îî‚îÄ‚îÄ README.md            # Descripci√≥n del proyecto
```

## üõ†Ô∏è Instalaci√≥n y Requisitos

Este proyecto utiliza las siguientes tecnolog√≠as y bibliotecas:

- **Lenguaje**: Python
- **Bibliotecas**:
  - [pandas](https://pandas.pydata.org/)
  - [numpy](https://numpy.org/)
  - [matplotlib](https://matplotlib.org/)
  - [seaborn](https://seaborn.pydata.org/)
  - [scikit-learn](https://scikit-learn.org/)
  - [xgboost](https://xgboost.readthedocs.io/)
  - [joblib](https://joblib.readthedocs.io/)
  
Puedes instalar las bibliotecas utilizando tu gestor de paquetes favorito.

## üìä Resultados e Insights

### **1. Logistic Regression**
La regresi√≥n log√≠stica ofrece un desempe√±o b√°sico con un **AUC de 0.80**, siendo el modelo menos efectivo en discriminar entre las clases.  
- **Errores:** 65 falsos positivos y 76 falsos negativos.  
- **Ventajas:** Simplicidad y velocidad, √∫til como punto de partida o referencia.  
- **Desventajas:** No captura relaciones complejas, lo que lo hace menos confiable para problemas donde la clase positiva es crucial.  
- **Conclusi√≥n:** Adecuado solo para problemas simples o como modelo interpretativo preliminar.



### **2. √Årbol de Decisi√≥n**
El √°rbol de decisi√≥n mejora significativamente sobre Logistic Regression, logrando un **AUC de 0.90** y reduciendo los errores.  
- **Errores:** 28 falsos positivos y 45 falsos negativos.  
- **Ventajas:** Interpretable y capaz de identificar patrones m√°s complejos.  
- **Desventajas:** Propenso al sobreajuste y menos eficiente para problemas grandes o complejos.  
- **Conclusi√≥n:** √ötil para tareas donde la interpretabilidad es importante, pero no tan preciso como otros modelos m√°s avanzados.



### **3. Random Forest**
Random Forest es el modelo m√°s robusto, con un **AUC sobresaliente de 0.98** y un excelente equilibrio en su matriz de confusi√≥n.  
- **Errores:** 1 falso positivo y 36 falsos negativos.  
- **Ventajas:** Alta precisi√≥n, excelente para manejar datos complejos y m√∫ltiples caracter√≠sticas.  
- **Desventajas:** Indicios de sobreajuste (100% de precisi√≥n en entrenamiento), requiere ajuste de hiperpar√°metros.  
- **Conclusi√≥n:** Ideal para problemas donde la precisi√≥n es cr√≠tica, aunque es necesario ajustar par√°metros para evitar sobreajuste.



### **4. Gradient Boosting**
Gradient Boosting combina precisi√≥n y generalizaci√≥n de manera eficiente, logrando un **AUC de 0.95**.  
- **Errores:** 13 falsos positivos y 38 falsos negativos.  
- **Ventajas:** Menos propenso al sobreajuste que Random Forest, balance entre rendimiento y eficiencia.  
- **Desventajas:** Ligeramente menos preciso que Random Forest.  
- **Conclusi√≥n:** Opci√≥n confiable para problemas complejos, especialmente cuando se busca un equilibrio entre precisi√≥n y uso de recursos.



### **5. XGBoost**
XGBoost es muy similar a Gradient Boosting en desempe√±o, con un **AUC ligeramente superior de 0.96**.  
- **Errores:** 10 falsos positivos y 42 falsos negativos.  
- **Ventajas:** Flexibilidad en optimizaci√≥n de hiperpar√°metros, rapidez en entrenamiento, ideal para escenarios con recursos limitados.  
- **Desventajas:** Rendimiento ligeramente inferior a Random Forest.  
- **Conclusi√≥n:** Excelente opci√≥n para problemas que requieren procesamiento r√°pido y eficiente.


### **Conclusi√≥n General**
- **Mejor Modelo:** **Random Forest** se destaca como el modelo m√°s preciso, ideal para problemas donde los errores m√≠nimos son cr√≠ticos. Sin embargo, requiere ajustes para reducir el sobreajuste.  
- **Alternativas S√≥lidas:** **Gradient Boosting y XGBoost** ofrecen un excelente equilibrio entre rendimiento y eficiencia, siendo m√°s generalizables y menos propensos al sobreajuste.  
- **Modelos B√°sicos:** Logistic Regression y √Årbol de Decisi√≥n son adecuados para tareas m√°s simples o como referencias iniciales, pero no son suficientemente potentes para problemas complejos o de alta dimensionalidad.

## üîÑ Pr√≥ximos Pasos y Contribuciones

Mejoras y extensiones futuras incluyen:
- Refinar los modelos predictivos con caracter√≠sticas adicionales y t√©cnicas avanzadas.
- Explorar relaciones causales entre la satisfacci√≥n laboral y la retenci√≥n.

¬°Las contribuciones al proyecto son bienvenidas! Puedes:
- Enviar un **pull request** para mejoras en el c√≥digo.
- Abrir **issues** para preguntas, sugerencias o reportes de errores.

## ü§ù Cr√©ditos

Este proyecto forma parte de una iniciativa m√°s amplia para explorar soluciones basadas en datos en la gesti√≥n organizacional. Agradecimientos especiales a todos los colaboradores que hicieron posible este proyecto.

---
